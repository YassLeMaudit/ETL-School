# Simple Kafka Tutorial (EV Support Tickets)

This guide shows how to run the lightweight Kafka-like tooling that ships with the session project. All examples use the car-support dataset generated by `data_generator.py`.

## Prerequisites
- Python 3.8 or newer available in your shell
- The current working directory is `C:\Users\33668\Documents\Albert school Msc2\ETL Warehouse\session3`
- The virtualenv (if any) already has the required packages installed (`pip install -r requirements.txt` or equivalent)

## Key Files
- `simple_kafka_setup.py` - creates the in-memory broker backed by SQLite and runs the smoke test
- `simple_publish_data.py` - publishes JSON lines from stdin into a topic
- `simple_consume_data.py` - prints messages from a topic and supports consumer groups
- `data_generator.py` - produces EV support ticket samples (used as a data source)

## Step-by-Step Runbook

### 1. Sanity-check the broker
This confirms the broker, producer, and consumer can interact end to end.

```powershell
python simple_kafka_setup.py
```
You should see three sample car-support messages published and consumed, followed by a clean shutdown.

### 2. Publish sample tickets
Use the generator to stream EV support tickets into the broker.

```powershell
# publish a single ticket
python data_generator.py 1 | python simple_publish_data.py

# publish a batch of ten
python data_generator.py 10 | python simple_publish_data.py

# stress-test with a hundred or a thousand
python data_generator.py 100 | python simple_publish_data.py
python data_generator.py 1000 | python simple_publish_data.py
```
The publisher reports how many tickets were accepted and the current queue depth.

### 3. Consume tickets in real time
Run a consumer in one terminal and publish in another.

```powershell
# Terminal A
python simple_consume_data.py

# (Optional) auto-stop after five messages (PowerShell)
$env:KAFKA_MAX_MESSAGES = '5'
python simple_consume_data.py

# Terminal B
python data_generator.py 5 | python simple_publish_data.py
```
The consumer prints each ticket with its transaction id, driver details, and vehicle information.

### 4. Demo load balancing with two consumers
Start two consumers with different group ids so they split the workload.

```powershell
# Terminal A
$env:KAFKA_CONSUMER_GROUP = 'consumer_1'
$env:KAFKA_MAX_MESSAGES = '10'
python simple_consume_data.py

# Terminal B
$env:KAFKA_CONSUMER_GROUP = 'consumer_2'
$env:KAFKA_MAX_MESSAGES = '10'
python simple_consume_data.py

# Terminal C
python data_generator.py 50 | python simple_publish_data.py
```
When both consumers stop, check how many messages each handled:

```powershell
python -c "import sqlite3; conn = sqlite3.connect('simple_kafka.db'); print(conn.execute('SELECT claimed_by, COUNT(*) FROM messages GROUP BY claimed_by').fetchall()); conn.close()"
```

### 5. Monitor topic statistics
Inspect queue depth, consumer count, and total messages at any time.

```powershell
python -c "from simple_kafka_setup import broker; print(broker.get_topic_stats('car_support_tickets'))"
```

### 6. Reset the environment (optional)
To start fresh, delete the SQLite file before running more tests.

```powershell
Remove-Item simple_kafka.db
```

## Notes
- `data_generator.py` emits timezone-naive timestamps and raises a Python deprecation warning; this does not affect the tutorial.
- All scripts are ASCII-only and safe to run multiple times.
- If you switch shells, adapt environment variable commands (for example `set VAR=value` in `cmd.exe`).
